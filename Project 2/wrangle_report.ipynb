{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling procedure has been completed on the datasets obtained from “WeRateDogs”. There have been 3 main stages:\n",
    "\n",
    "* Data gathering:\n",
    "\n",
    "At this step ,i've gathered data from udacity 'twitter archive enhanced.csv' using manual download and 'image_predictions.csv' using programmatically mathod.i've also gathered additional data using twitter API such as retweet_count and favoriate_count.\n",
    "\n",
    "* Data assessment:\n",
    "at this step, i've assessed data both visually and programmatically.Thia step is mainly about finding errors and mistakes either in the datatype or in data itself. The problems were as follow :\n",
    "###### Quality issues\n",
    "\n",
    "##### `twitter_archive_enhanced` table\n",
    "\n",
    "\n",
    "1 Erroneous datatypes (timestamp, source , rating_numerator, rating_denominator ).\n",
    "\n",
    "2 Clean text column.\n",
    "\n",
    "3 Only original tweets.\n",
    "\n",
    "4 Incorrect values in the column source hidden in HTML code.\n",
    "\n",
    "5 Incorrect values in the column name.\n",
    "\n",
    "6 Incorrect values in the column rating_numerator, rating_denominator. \n",
    "\n",
    "7 Convert the string \"None\" to a proper None .(Unknown)\n",
    "\n",
    "\n",
    "##### `image_predictions` table\n",
    "\n",
    "8 Erroneous datatypes of new created column dog_stage.\n",
    "\n",
    "9 Incorrect predictions in p1, p2 and p3.\n",
    "\n",
    "10 Missing rows (2075 instead of 2356).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### `tweet_df` table\n",
    "\n",
    "11 Missing rows (2327 instead of 2356).\n",
    "\n",
    "###### Tidiness issues\n",
    "\n",
    "##### `twitter_archive_enhanced` table\n",
    "\n",
    "1 Create new column dog_stage instead 4 different columns (doggo, floofer, pupper, and puppo).\n",
    "\n",
    "2 Drop unnecessary columns.\n",
    "\n",
    "\n",
    "##### `image_predictions` table\n",
    "\n",
    "3 Create new column dog_breed instead 3 different columns (p1, p2 and p3).\n",
    "\n",
    "##### `tweet_df` table\n",
    " \n",
    "4 Combine tweet_df and twitter_archive_enhanced and image_redictions.\n",
    "\n",
    "\n",
    "* Data cleaning:\n",
    "\n",
    "At this step, i've clean the data following the assessing that i've made in order to explore the data. This phase contained 3 main step; define , code and test .\n",
    "\n",
    "\n",
    "This a sample of the dataset after the cleaning.\n",
    "\n",
    "<img src=\"tweet_clean_sample.png\">\n",
    "\n",
    "* Analysis and visualization :\n",
    "\n",
    "Once the data has be gathered assessed and cleaned , it's time to analyse and visualize.I've asked some questions and tried to answer them such as Top 10 dog breeds, top 10 dog names , correlation between variables, peak hours...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
